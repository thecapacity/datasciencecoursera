| Count Outcomes. (Slides for this and other Data Science courses may be found at github
| https://github.com/DataScienceSpecialization/courses. If you care to use them, they must be downloaded as a zip file
| and viewed locally. This lesson corresponds to Regression_Models/03_03_countOutcomes.)


| Many data take the form of counts. These might be calls to a call center, number of flu cases in an area, or number of
| cars that cross a bridge. Data may also be in the form of rates, e.g., percent of children passing a test. In this
| lesson we will use Poisson regression to analyze daily visits to a web site as the web site's popularity grows, and to
| analyze the percent of visits which are due to references from a different site.

| Visits to a web site tend to occur independently, one at a time, at a certain average rate. The Poisson distribution
| describes random processes of this type. A Poisson process is characterized by a single parameter, the expected rate
| of occurrence, which is usually called lambda. In our case, lambda will be expected visits per day. Of course, as the
| web site becomes more popular, lambda will grow. In other words, our lambda will depend on time. We will use Poisson
| regression to model this dependence.

| Somwhat remarkably, the variance of a Poisson process has the same value as its mean, lambda. You can quickly
| illustrate this by generating, say, n=1000 samples from a Poisson process using R's rpois(n, lambda) and calculating
| the sample variance. For example, type var(rpois(1000, 50)). The sample variance won't be exactly equal to the
| theoretical value, of course, but it will be fairly close.

| The counts generated by a Poisson process are, strictly speaking, slightly different than the normalized sums of the
| Central Limit Theorem. However, the counts in a given period of time will represent sums of larger numbers of terms as
| lambda increases. In fact, it can be formally shown that for large lambda a Poisson distribution is well approximated
| by a normal. The figure illustrates this effect. It shows progression from a sparse, asymetric, Poisson probability
| mass function on the left, to a dense, bell-shaped curve on the right as lambda varies from 2 to 100.

| In a Poisson regression, the log of lambda is assumed to be a linear function of the predictors. Since we will try to
| model the growth of visits to a web site, the log of lambda will be a linear function of the date: log(lambda) = b0 +
| b1*date. This implies that the average number of hits per day, lambda, is exponential in the date: lambda =
| exp(b0)*exp(b1)^date. Exponential growth is also suggested by the smooth, black curve drawn though the data. Thus
| exp(b1) would represent the percentage by which visits grow per day.

head(hits)
        date visits simplystats
1 2011-01-01      0           0
2 2011-01-02      0           0
3 2011-01-03      0           0
4 2011-01-04      0           0
5 2011-01-05      0           0
6 2011-01-06      0           0


| Our dates are represented in terms of R's class, Date. Verify this by typing class(hits[,'date']), or something
| equivalent.

| The arithmetic [numericly sequential/increasing when converted to an int] properties of Dates allow us to use them as predictors. We'll use Poisson regression to predict
| log(lambda) as a linear function of date in a way which maximizes the likelihood of the counts we actually see. Our
| formula will be visits ~ date. Since our outcomes (visits) are counts, our family will be 'poisson', and our third
| argument will be the data, hits. Create such a model and store it in a variable called mdl using the following
| expression or something equivalent, mdl <- glm(visits ~ date, poisson, hits).

> summary(mdl)

Call:
glm(formula = visits ~ date, family = poisson, data = hits)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-5.0466  -1.5908  -0.3198   0.9128  10.6545  

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -3.275e+01  8.130e-01  -40.28   <2e-16 ***
date         2.293e-03  5.266e-05   43.55   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 5150.0  on 730  degrees of freedom
Residual deviance: 3121.6  on 729  degrees of freedom
AIC: 6069.6

Number of Fisher Scoring iterations: 5

| Both coefficients are significant, being far more than two standard errors from zero. The Residual deviance is also
| very significantly less than the Null, indicating a strong effect. (Recall that the difference between Null and
| Residual deviance is approximately chi-square with 1 degree of freedom.) The Intercept coefficient, b0, just
| represents log average hits on R's Date 0, namely January 1, 1970. We will ignore it and focus on the coefficient of
| date, b1, since exp(b1) will estimate the percentage at which average visits increase per day of the site's life.

| Get the 95% confidence interval for exp(b1) by exponentiating confint(mdl, 'date')

> exp(confint(mdl, 'date'))
Waiting for profiling to be done...
   2.5 %   97.5 % 
1.002192 1.002399 

| Visits are estimated to increase by a factor of between 1.002192 and 1.002399 per day. That is, between 0.2192% and
| 0.2399% per day. This actually represents more than a doubling every year.

| Our model looks like a pretty good description of the data, but no model is perfect and we can often learn about a
| data generation process by looking for a model's shortcomings. As shown in the figure, one thing about our model is
| 'zero inflation' in the first two weeks of January 2011, before the site had any visits. The model systematically
| overestimates the number of visits during this time. A less obvious thing is that the standard deviation of the data
| may be increasing with lambda faster than a Poisson model allows. This possibility can be seen in the rightmost plot
| by visually comparing the spread of green dots with the standard deviation predicted by the model (black dashes.)
| Also, there are four or five bursts of popularity during which the number of visits far exceeds two standard
| deviations over average. Perhaps these are due to mentions on another site.


lambda <- mdl$fitted.values[704]

| The number of visits explained by our model on December 4, 2012 are those of a Poisson random variable with mean
| lambda. We can find the 95th percentile of this distribution using qpois(.95, lambda). Try this now.

| So, 95% of the time we would see 33 or fewer visits, hence 30 visits would not be rare according to our model. It
| would seem that on December 4, 2012, the very high number of visits was due to references from Simply Statistics. To
| gauge the importance of references from Simply Statistics we may wish to model the proportion of traffic such
| references represent. Doing so will also illustrate the use of glm's parameter, offset, to model frequencies and
| proportions.

| A Poisson process generates counts, and counts are whole numbers, 0, 1, 2, 3, etc. A proportion is a fraction. So how
| can a Poisson process model a proportion? The trick is to include the denominator of the fraction, or more precisely
| its log, as an offset. Recall that in our data set, 'simplystats' is the visits from Simply Statistics, and 'visits'
| is the total number of visits. We would like to model the fraction simplystats/visits, but to avoid division by zero
| we'll actually use simplystats/(visits+1). A Poisson model assumes that log(lambda) is a linear combination of
| predictors. Suppose we assume that log(lambda) = log(visits+1) + b0 + b1*date. In other words, if we insist that the
| coefficient of log(visits+1) be equal to 1, we are predicting the log of mean visits from Simply Statistics as a
| proportion of total visits: log(lambda/(visits+1)) = b0 + b1*date.

| glm's parameter, offset, has precisely this effect. It fixes the coefficient of the offset to 1. To create a model for
| the proportion of visits from Simply Statistics, we let offset=log(visits+1). Create such a Poisson model now and
| store it as a variable called mdl2.

| Enter mdl2 <- glm(simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1)), or something
| equivalent.

| Although summary(mdl2) will show that the estimated coefficients are significantly different than zero, the model is
| actually not impressive. We can illustrate why by looking at December 4, 2012, once again. On that day there were 64
| actual visits from Simply Statistics. However, according to mdl2, 64 visits would be extremely unlikely. You can
| verify this weakness in the model by finding mdl2's 95th percentile for that day. Recalling that December 4, 2012 was
| sample 704, find qpois(.95, mdl2$fitted.values[704]).


